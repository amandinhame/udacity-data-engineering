# Data Quality

## Data Linage

Describes the discrete steps involved in the creation, movement and calculation of that dataset.
It is important to:
* Build confidence in data consumers that the pipelines are designed properly
* Define metrics
* Debugging

## Data Pipeline Schedules

Scope based on:
* Size of the data
* Frequency of data
* Related datesets

## Data Partition

Data partition is the process of isolating data to be analyzed by one or more attributes, such as time, logical type or data size. It often leads to faster and reliable pipelines.

## Data Quality

Examples of data quality requirements:
* Data must be of certain size
* Data must be accurate to some margin of error
* Data must arrive within a given timeframe from the start of execution
* Pipelines must run on a particular schedule
* Data must not contain any sensitive information